{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BV-6hkYhxf0w"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yqz7K9Id5R6w"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "AbKflLnuDTrG",
    "outputId": "934735e3-fc85-455b-93c9-f9bd80afdc5a"
   },
   "outputs": [],
   "source": [
    "# DOWNLOAD THE VGG16 MODEL\n",
    "import torchvision.models as models\n",
    "vgg16=models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"./train/\"\n",
    "# DATASET OF 20K IMAGES FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpUDQE9LzDhe"
   },
   "outputs": [],
   "source": [
    "#PARAMETERS FOR LOADING DATASET\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 32\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this.\n",
    "image_size = 64\n",
    "image_size_224 = 224\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 699\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate for optimizers\n",
    "lr = 0.001\n",
    "\n",
    "# Beta hyperparam for Adam optimizers\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "colab_type": "code",
    "id": "dpFSGUbx13rt",
    "outputId": "55551fd4-7a7f-4ab2-ac55-b96035683204"
   },
   "outputs": [],
   "source": [
    "# Create the dataset, dataset stores 64*64*3 images and 224*224*3 images\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "dataset_224= dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size_224),\n",
    "                               transforms.CenterCrop(image_size_224),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader for both datasets\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "dataloader_224 = torch.utils.data.DataLoader(dataset_224, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# # Plot some training images\n",
    "# real_batch = next(iter(dataloader))\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "# real_batch = next(iter(dataloader_224))\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:224], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqzAMJ6UDI8w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Running on: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first 14 layers of vgg16\n",
    "first_14_fun_cuda=lambda x:vgg16.classifier.train(mode=False).to(device)[:2](vgg16.avgpool(vgg16.features.train(mode=False).to(device)(x)).to(device).detach().reshape(-1,25088))\n",
    "def phi(image):\n",
    "  ftr_img=first_14_fun_cuda(image.to(device)).cpu().detach()\n",
    "  return ftr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WDd0_SxQz8ZQ",
    "outputId": "3632d8b2-7d5d-411e-e12b-c9cf57e47ab8"
   },
   "outputs": [],
   "source": [
    "#TEST CELL\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "fixed_noise = torch.randn(2, 3, 224, 224, device=device)\n",
    "test=phi(fixed_noise).reshape(-1,4096)\n",
    "assert test.shape==(2,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSL9LKb6XvO3"
   },
   "outputs": [],
   "source": [
    "#Eps returns the relu3_3 output of vgg16 model\n",
    "E=lambda x:vgg16.features.train(mode=False).cuda()[:16](x)\n",
    "def Eps(image):\n",
    "  ftr_img=E(image.cuda()).cpu()\n",
    "  return ftr_img\n",
    "phi_Eps_16=lambda x:vgg16.classifier.train(mode=False).to(device)[:2](vgg16.avgpool(vgg16.features[16:].train(mode=False).to(device)(x)).to(device).detach().reshape(-1,25088))\n",
    "#phi_Eps applies on the Eps output of an image to generate the phi output\n",
    "def phi_Eps(image):\n",
    "  ftr_img=phi_Eps_16(image.to(device)).cpu().detach()\n",
    "  return ftr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST CELL\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "fixed_noise = torch.randn(2, 3, 224, 224, device=device)\n",
    "test=phi_Eps(Eps(fixed_noise))\n",
    "test2=phi(fixed_noise)\n",
    "assert np.allclose(test.numpy(),test2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBKfxGcrk3TZ"
   },
   "outputs": [],
   "source": [
    "#returns a matrix which can be used to apply PCA on PyTorch Tensors\n",
    "def PCA_fit(X, k=2):\n",
    " # preprocess the data\n",
    " X_mean = torch.mean(X,0)\n",
    " X = X - X_mean.expand_as(X)\n",
    " # svd\n",
    " U,S,V = torch.svd(torch.t(X))\n",
    " return U[:,:k]\n",
    "# Takes as input a tensor and pca_mat to generate the transformed tensor\n",
    "def PCA_transform(X,U):\n",
    "  return torch.mm(X,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Can be used to generate the pca_mat matrix\n",
    "# i=0\n",
    "# first=False\n",
    "# for batch in dataloader_224:\n",
    "#   if first==False:\n",
    "#     first=True\n",
    "#     phi_x=phi(batch[0]).reshape(-1,4096)\n",
    "#   else:\n",
    "#     phi_x=torch.cat((phi_x,phi(batch[0]).reshape(-1,4096)))\n",
    "#   if i%32==0:\n",
    "#     print(i)\n",
    "#   i=i+1\n",
    "# PATH_PCAMAT='./CHECKPOINT/pcamat.pth'\n",
    "# pca_mat=PCA_fit(phi_x,k=699)\n",
    "# torch.save({'pcamat':pca_mat},PATH_PCAMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7idg801lRtn"
   },
   "outputs": [],
   "source": [
    "PATH_PCAMAT='./CHECKPOINT/pcamat.pth'\n",
    "checkpoint=torch.load(PATH_PCAMAT)\n",
    "pca_mat=checkpoint['pcamat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5Q0wlGIRM7x"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TALWIVPN4oC7"
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "        # WE USED THIS FOR FASTER CONVERGENCE \n",
    "        # ACTUAL PAPER USES: nn.init.normal_(m.weight.data, 1.0, 0.01) \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTz7clRm4v2z"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "OF4tF97h5DDS",
    "outputId": "a3783f4a-3f0b-43ed-ca84-a2a26f3cb239"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(699, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GTmJ2c86T5S"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "dwima5q26B6q",
    "outputId": "693b0a2a-cb70-4544-a5d2-9c3558103f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiSIWbXB6BuS"
   },
   "outputs": [],
   "source": [
    "# Initialize Loss functions\n",
    "criterion = nn.BCELoss()\n",
    "crit_mse = nn.MSELoss()\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 0.99 ##\n",
    "fake_label = 0.01 ##\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALISATION CODE\n",
    "random.seed(1221)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "# # Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "LAMBDA_DIS=100\n",
    "LAMBDA_ADV=100\n",
    "LAMBDA_FEA=0.01\n",
    "LAMBDA_STI=2e-6\n",
    "epoch_ck=0\n",
    "upsampler = nn.UpsamplingBilinear2d(size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV_PATH='./CHECKPOINT/savedmodel.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD WEIGHTS OF PREVIOUS TRAINING SESSION\n",
    "LD_PATH='./CHECKPOINT/pretrained_stimuli_6L.pth'\n",
    "checkpoint = torch.load(LD_PATH)\n",
    "netG.load_state_dict(checkpoint['modelG_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['modelD_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "epoch_ck = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zxMNIwZqGyM7",
    "outputId": "e83ef9f2-4ded-4752-d0ed-d2fc6598c2e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[17/100][0/673]\tLoss_D: 5.6166 / 7.6171\tLoss_G:   0.0357 / 0.0000 \tD(x): 0.9555\tD(G(z)): 0.0118 / 0.0129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-49bc891e6ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mG_z_224\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupsampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_z\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Upsample it to pass through vgg16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0meps_G_z_224\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_z_224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Get features of Generator output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0merrG_fea\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLAMBDA_FEA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcrit_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps_real_cpu_224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps_G_z_224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Get feature loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0merrG_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "saveNumber=0\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(epoch_ck,num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, dataTuple in enumerate(zip(dataloader,dataloader_224), 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "       \n",
    "        \n",
    "        data=dataTuple[0]\n",
    "        data_224=dataTuple[1]\n",
    "        \n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        real_cpu_224 = data_224[0].to(device)\n",
    "        b_size = real_cpu_224.size(0)\n",
    "        \n",
    "        # Generate batch of latent vectors\n",
    "        with torch.no_grad():\n",
    "            eps_real_cpu_224=Eps(real_cpu_224)\n",
    "            phi_real_cpu_224=phi_Eps(eps_real_cpu_224)\n",
    "            z=PCA_transform(phi_real_cpu_224,pca_mat)\n",
    "            z=z.reshape(z.shape[0],z.shape[1],1,1).to(device)\n",
    "            noise=z\n",
    "        \n",
    "        netD.zero_grad() # Init gradients to 0\n",
    "        ## Train with all-real batch\n",
    "        label = torch.full((b_size,), real_label, device=device)\n",
    "        output = netD(real_cpu).view(-1) # Forward pass real batch through D\n",
    "        errD_real = LAMBDA_DIS*criterion(output, label) # Calculate loss on all-real batch\n",
    "        errD_real.backward() # Calculate gradients for D in backward pass\n",
    "        D_x = output.mean().item() # For tracking progress\n",
    "\n",
    "        ## Train with all-fake batch        \n",
    "        fake = netG(noise) # Generate fake image batch with G\n",
    "        label.fill_(fake_label) # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1) # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = LAMBDA_DIS*criterion(output, label) # Calulate error for this batch\n",
    "        errD_fake.backward() # Calculate the gradients for this batch\n",
    "        D_G_z1 = output.mean().item() # For tracking progress\n",
    "        \n",
    "        errD = errD_real + errD_fake # Add the gradients from the all-real and all-fake batches\n",
    "        optimizerD.step() # Update D\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z))) + LOSS_FEA + LOSS_STI\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake).view(-1)# Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        errG_a = LAMBDA_ADV * criterion(output, label)# Calculate G's loss based on this output\n",
    "        errG_a.backward()# Calculate gradients for G\n",
    "        \n",
    "        \n",
    "        G_z=netG(noise.detach()) # Generate an image\n",
    "        G_z_224=upsampler(G_z)  # Upsample it to pass through vgg16\n",
    "        eps_G_z_224=Eps(G_z_224)# Get features of Generator output \n",
    "        errG_fea= LAMBDA_FEA*crit_mse(eps_real_cpu_224,eps_G_z_224)# Get feature loss\n",
    "        errG_fea.backward()# Backward pass \n",
    "        \n",
    "        G_z2=netG(noise.detach()) # Generate an image\n",
    "        errG_sti = LAMBDA_STI*crit_mse(real_cpu,G_z2)# Get stimuli loss\n",
    "        errG_sti.backward() #Backward Pass\n",
    "\n",
    "        errG=errG_a+errG_fea+errG_sti # Total loss\n",
    "        D_G_z2 = output.mean().item() # For tracking progress\n",
    "        \n",
    "        optimizerG.step() # Update parameters of Generator\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 100  == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f / %.4f\\tLoss_G:   %.4f / %.4f \\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD_fake.item(), errD_real.item(), errG_fea.item(),errG_sti.item(), D_x, D_G_z1, D_G_z2))\n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "        # Periodically save weights for retraining\n",
    "        if(iters%1000==0):\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'modelG_state_dict': netG.state_dict(),\n",
    "            'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "            'errG': errG,\n",
    "            'modelD_state_dict': netD.state_dict(),\n",
    "            'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "            'errD': errD,\n",
    "            }, SV_PATH)\n",
    "            saveNumber += 1\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "QBmLy3b7dgmf",
    "outputId": "d44d5b38-67af-4e91-fda6-f03d2c17b83f"
   },
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "# LOAD TEST DATASET\n",
    "dataset = dset.ImageFolder(root='./test/',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size_224),\n",
    "                               transforms.CenterCrop(image_size_224),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATION METRICS\n",
    "import kornia\n",
    "def struct_similiarity(x,y):\n",
    "    ssim=kornia.losses.SSIM(3)\n",
    "    loss=torch.mean(ssim(x,y))\n",
    "    return loss\n",
    "def pearson_coefficient(x,y):\n",
    "    vx = x - torch.mean(x)\n",
    "    vy = y - torch.mean(y)\n",
    "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    return cost\n",
    "featureExtractor=lambda x:vgg16.classifier[:5].train(mode=False).to(device)[:2](vgg16.avgpool(vgg16.features.train(mode=False).to(device)(x)).to(device).detach().reshape(-1,25088))\n",
    "def feature_similarity(x,y):\n",
    "    f1=featureExtractor(x)\n",
    "    f2=featureExtractor(y)\n",
    "    euclidean = nn.PairwiseDistance(p=2)\n",
    "    cost = euclidean(f1,f2).mean()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure=np.array([])\n",
    "pearson=np.array([])\n",
    "feature=np.array([])\n",
    "\n",
    "for i, data in enumerate(dataloader_test, 0):\n",
    "    batch=data[0].to(device)\n",
    "    with torch.no_grad():\n",
    "        z=PCA_transform(phi(batch),pca_mat)\n",
    "        z=z.reshape(z.shape[0],z.shape[1],1,1).to(device)\n",
    "        real=batch\n",
    "        fake =upsampler(netG(z).detach().to(device))\n",
    "    ssim=struct_similiarity(real,fake).cpu().detach().numpy()\n",
    "    corr=pearson_coefficient(real,fake).cpu().detach().numpy()\n",
    "    fsim=feature_similarity(real,fake).cpu().detach().numpy()\n",
    "    \n",
    "    structure=np.append(structure,ssim)\n",
    "    pearson=np.append(pearson,corr)\n",
    "    feature=np.append(feature,fsim)\n",
    "    if i>10:\n",
    "        break\n",
    "\n",
    "s_mean=np.mean(structure)\n",
    "p_mean=np.mean(pearson)\n",
    "f_mean=np.mean(feature)\n",
    "\n",
    "s_sd=np.std(structure)\n",
    "p_sd=np.std(pearson)\n",
    "f_sd=np.std(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structural Similarity:  0.28947963068882626  +-  0.005695663162144385\n",
      "Pearson Correlation:  0.7751902192831039  +-  0.015463066628726884\n",
      "Feature Similarity:  37.65902773539225  +-  0.7089358121369557\n"
     ]
    }
   ],
   "source": [
    "print('Structural Similarity: ',s_mean,' +- ',s_sd)\n",
    "print('Pearson Correlation: ',p_mean,' +- ',p_sd)\n",
    "print('Feature Similarity: ',f_mean,' +- ',f_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VISUALISE SOME OF THE OUTPUTS\n",
    "# real_batch = next(iter(dataloader_test))\n",
    "# with torch.no_grad():\n",
    "#     k=28  # VARY K to display different images\n",
    "#     z=PCA_transform(phi(real_batch[0]),pca_mat)\n",
    "#     z=z[k].reshape(1,z.shape[1],1,1).to(device)\n",
    "#     real=real_batch[0][k]\n",
    "#     fake = netG(z).detach().to(device)\n",
    "# real_img=vutils.make_grid(real, padding=2, normalize=True)\n",
    "# fake_img=vutils.make_grid(fake, padding=2, normalize=True)\n",
    "# plt.figure(0)\n",
    "# plt.imshow(real_img.cpu().permute(1, 2, 0))\n",
    "# plt.figure(1)\n",
    "# plt.imshow(fake_img.cpu().permute(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "phi_INV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
